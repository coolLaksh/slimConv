{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SLIM_CONVOLUTION_1D(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels:int,\n",
    "                 reduction:int,\n",
    "                 kernel_size:int,\n",
    "                 stride:int=1,\n",
    "                 padding:int=0,\n",
    "                 dilation:int=1,\n",
    "                 groups:int=1,\n",
    "                 convolution_type:str=\"CLASSIC\",\n",
    "                 rank:int=1,\n",
    "                 bias:bool=False,\n",
    "                 *args, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        __CONVOLUTIONS = {\"DSC\": DEPTHWISE_SEPERABLE_CONVOLUTION_1D,\n",
    "                          \"LRC\": LOW_RANK_CONVOLUTION_1D,\n",
    "                          \"FUSED\": FUSED_CONVOLUTION_BN_1D,\n",
    "                          \"CLASSIC\": CONVOLUTION_1D}\n",
    "\n",
    "        self.TYPE_C = convolution_type\n",
    "        if self.TYPE_C not in [\"DSC\", \"LRC\", \"FUSED\", \"CLASSIC\"]: raise Exception(\"Only implemented for [DSC, LRC, FUSED, CLASSIC]\")\n",
    "        \n",
    "        self.INPUT_CHANNEL = in_channels\n",
    "        self.REDUCTION = reduction\n",
    "        self.KERNEL_SIZE = kernel_size\n",
    "        self.RANK = rank\n",
    "        self.BIAS = bias\n",
    "        self.STRIDE = stride\n",
    "        self.DILATION = dilation\n",
    "        self.PADDING = padding\n",
    "        self.GROUPS = groups\n",
    "\n",
    "\n",
    "        self.SQUEEZE_EXCITE = nn.Sequential(nn.AdaptiveAvgPool1d(1),\n",
    "                                            __CONVOLUTIONS[self.TYPE_C](in_channels=self.INPUT_CHANNEL,\n",
    "                                                                        out_channels=int(self.INPUT_CHANNEL/2),\n",
    "                                                                        kernel_size=1,\n",
    "                                                                        rank=self.RANK,\n",
    "                                                                        **kwargs),\n",
    "                                            nn.ReLU(),\n",
    "                                            __CONVOLUTIONS[self.TYPE_C](in_channels=int(self.INPUT_CHANNEL/2),\n",
    "                                                                        out_channels=self.INPUT_CHANNEL,\n",
    "                                                                        kernel_size=1,\n",
    "                                                                        rank=self.RANK,\n",
    "                                                                        **kwargs))\n",
    "        \n",
    "        self.BRANCH1_CONV = __CONVOLUTIONS[self.TYPE_C](in_channels=int(self.INPUT_CHANNEL/2),\n",
    "                                                        out_channels=int(self.INPUT_CHANNEL/2),\n",
    "                                                        kernel_size=self.KERNEL_SIZE,\n",
    "                                                        rank=self.RANK,\n",
    "                                                        bias=self.BIAS,\n",
    "                                                        stride=self.STRIDE,\n",
    "                                                        padding=self.PADDING,\n",
    "                                                        dilation=self.DILATION,\n",
    "                                                        groups=self.GROUPS,\n",
    "                                                        **kwargs)\n",
    "\n",
    "        self.BRANCH2_CONV = nn.Sequential(__CONVOLUTIONS[self.TYPE_C](in_channels=int(self.INPUT_CHANNEL/2),\n",
    "                                                                      out_channels=int(self.INPUT_CHANNEL/2),\n",
    "                                                                      kernel_size=1,\n",
    "                                                                      rank=self.RANK,\n",
    "                                                                      bias=self.BIAS,\n",
    "                                                                      stride=self.STRIDE,\n",
    "                                                                      padding=self.PADDING,\n",
    "                                                                      dilation=self.DILATION,\n",
    "                                                                      groups=self.GROUPS,\n",
    "                                                                      **kwargs),\n",
    "                                          __CONVOLUTIONS[self.TYPE_C](in_channels=int(self.INPUT_CHANNEL/2),\n",
    "                                                                      out_channels=int(self.INPUT_CHANNEL/self.REDUCTION),\n",
    "                                                                      kernel_size=self.KERNEL_SIZE,\n",
    "                                                                      rank=self.RANK,\n",
    "                                                                      bias=self.BIAS,\n",
    "                                                                      stride=self.STRIDE,\n",
    "                                                                      padding=self.PADDING,\n",
    "                                                                      dilation=self.DILATION,\n",
    "                                                                      groups=self.GROUPS,\n",
    "                                                                      **kwargs))\n",
    "         \n",
    "    def forward(self, INPUT):\n",
    "        if INPUT.shape[1]%2 != 0:\n",
    "            raise Exception(\"Channel must be even\")\n",
    "\n",
    "        W = self.SQUEEZE_EXCITE(INPUT)\n",
    "        W_F = W.flip(1)\n",
    "        \n",
    "        X1 = W*INPUT\n",
    "        O1 = X1.split(int(X1.shape[1]/2), dim=1)\n",
    "        O1 = torch.add(O1[0], O1[1])\n",
    "        O1 = self.BRANCH1_CONV(O1)\n",
    "        \n",
    "        X2 = W_F*INPUT\n",
    "        O2 = X2.split(int(X2.shape[1]/2), dim=1)\n",
    "        O2 = torch.add(O2[0], O2[1])\n",
    "        O2 = self.BRANCH2_CONV(O2)\n",
    "        \n",
    "        return torch.cat([O1, O2], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
